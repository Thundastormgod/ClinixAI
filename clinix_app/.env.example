# ClinixAI Mobile App Environment Variables
# Copy this to .env and fill in your values
# This file is used by the Flutter app for runtime configuration

# ==================== OPENROUTER (Primary Cloud AI) ====================
# Get your API key at: https://openrouter.ai/keys
# This enables hybrid local/cloud inference for complex medical cases
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# Default model for standard inference
# Options: openai/gpt-4o, anthropic/claude-3.5-sonnet, mistralai/mistral-large, meta-llama/llama-3.1-70b-instruct
OPENROUTER_DEFAULT_MODEL=anthropic/claude-3.5-sonnet

# Model for critical/emergency cases (requires highest accuracy)
OPENROUTER_CRITICAL_MODEL=openai/gpt-4o

# Cost-effective model for simple cases
OPENROUTER_SIMPLE_MODEL=meta-llama/llama-3.1-70b-instruct

# ==================== HUGGINGFACE (Model Downloads) ====================
# Required for downloading LiquidAI LFM2 models to device
# Get your token at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=hf_your-huggingface-token-here

# ==================== AI ROUTING CONFIG ====================
# Risk score threshold to trigger cloud inference (0.0 - 1.0)
AI_RISK_THRESHOLD=0.6

# Complexity score threshold to trigger cloud inference (0.0 - 1.0)
AI_COMPLEXITY_THRESHOLD=0.5

# Local confidence threshold below which to escalate to cloud (0.0 - 1.0)
AI_CONFIDENCE_ESCALATION_THRESHOLD=0.7

# Prefer local inference when possible (true/false)
AI_PREFER_LOCAL=true

# ==================== LOCAL LLM CONFIG ====================
# Default local model (lfm2_1_2b_rag, qwen3_06, qwen3_17, gemma3_270m)
LOCAL_LLM_MODEL=lfm2_1_2b_rag

# Maximum tokens for local inference
LOCAL_LLM_MAX_TOKENS=512

# Temperature for inference (0.0 - 1.0)
LOCAL_LLM_TEMPERATURE=0.3

# ==================== BACKEND API (Optional) ====================
# If connecting to ClinixAI backend server
API_BASE_URL=https://api.clinixai.health
API_VERSION=v1

# ==================== ANALYTICS (Optional) ====================
# Firebase Analytics (if using)
FIREBASE_PROJECT_ID=

# Sentry for error tracking
SENTRY_DSN=
