# ClinixAI Environment Variables
# Copy this to .env and fill in your values

# ==================== DATABASE ====================
POSTGRES_DB=clinixai
POSTGRES_USER=clinixai_user
POSTGRES_PASSWORD=clinixai_dev_password
DATABASE_URL=postgresql://clinixai_user:clinixai_dev_password@localhost:5432/clinixai

# ==================== REDIS ====================
REDIS_URL=redis://localhost:6379

# ==================== SECURITY ====================
JWT_SECRET=your-super-secret-jwt-key-change-in-production-minimum-32-chars
JWT_EXPIRES_IN=15m
JWT_REFRESH_EXPIRES_IN=7d

# ==================== AI / LLM PROVIDERS ====================
# OpenRouter (Unified Cloud API - supports GPT-4, Claude, Mistral, Llama)
# Get your API key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# OpenRouter Configuration
# Default model for standard inference (options: openai/gpt-4o, anthropic/claude-3.5-sonnet, mistralai/mistral-large, meta-llama/llama-3.1-70b-instruct)
OPENROUTER_DEFAULT_MODEL=anthropic/claude-3.5-sonnet

# Model for critical/emergency cases (highest accuracy)
OPENROUTER_CRITICAL_MODEL=openai/gpt-4o

# Cost-effective model for simple cases
OPENROUTER_SIMPLE_MODEL=meta-llama/llama-3.1-70b-instruct

# OpenRouter site info (for API tracking)
OPENROUTER_SITE_URL=https://clinixai.health
OPENROUTER_SITE_NAME=ClinixAI

# OpenAI (for high-accuracy cloud inference)
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic Claude (alternative cloud provider)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# HuggingFace (for Qwen/LiquidAI inference)
HUGGINGFACE_API_KEY=hf_your-huggingface-token-here

# ==================== QWEN MODEL (Primary Medical AI) ====================
# Custom HuggingFace Inference Endpoint for Qwen
# Format: https://your-endpoint-id.region.aws.endpoints.huggingface.cloud
# Leave empty to use default HuggingFace Inference API
QWEN_ENDPOINT_URL=

# Qwen model variant (qwen2.5-7b, qwen2.5-3b, qwen2.5-1.5b, qwen2.5-0.5b)
QWEN_MODEL=qwen2.5-7b

# ==================== LIQUIDAI MODEL (Efficient Edge AI) ====================
# Custom HuggingFace Inference Endpoint for LiquidAI
# Format: https://your-endpoint-id.region.aws.endpoints.huggingface.cloud
LIQUID_ENDPOINT_URL=

# LiquidAI model variant (lfm-7b, lfm-3b, lfm2-1.2b-rag)
LIQUID_MODEL=lfm-7b

# ==================== AI CONFIGURATION ====================
# Provider priority (comma-separated: qwen, liquid, huggingface, openai, anthropic)
AI_PROVIDER_PRIORITY=qwen,liquid,huggingface,openai,anthropic

# LangGraph settings
AI_CLOUD_RISK_THRESHOLD=0.6
AI_CLOUD_COMPLEXITY_THRESHOLD=0.5
AI_PREFER_LOCAL=true
AI_LOCAL_CONFIDENCE_THRESHOLD=0.7

# Local LLM settings (for edge inference)
LOCAL_LLM_MODEL_PATH=models/lfm2-1.2b-rag-q4_k_m.gguf
LOCAL_LLM_BACKEND=rule_based
LOCAL_LLM_MAX_TOKENS=256
LOCAL_LLM_TEMPERATURE=0.3

# ==================== SERVICES ====================
API_GATEWAY_PORT=3000
TRIAGE_SERVICE_PORT=8000
EHR_BRIDGE_PORT=3001
FHIR_SERVER_PORT=8080

# ==================== EXTERNAL EHR ====================
# OpenMRS (if connecting to existing instance)
OPENMRS_URL=http://localhost:8083/openmrs
OPENMRS_USER=admin
OPENMRS_PASSWORD=Admin123

# DHIS2 (if connecting to existing instance)
DHIS2_URL=https://play.dhis2.org/40.2.2
DHIS2_USER=admin
DHIS2_PASSWORD=district

# ==================== AWS (Production) ====================
AWS_REGION=af-south-1
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_S3_BUCKET=clinixai-images

# ==================== MONITORING ====================
SENTRY_DSN=https://your-sentry-dsn@sentry.io/project
LOG_LEVEL=debug
